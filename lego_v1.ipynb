{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in some tweets\n",
    "import csv\n",
    "jack_reader = csv.reader(open('data/realdonaldtrump.csv', 'r'))\n",
    "\n",
    "columns = next(jack_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jack_tweets = list(jack_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you Reno, Nevada. \n",
      "NOTHING will stop us in our quest to MAKE AMERICA SAFE AND GREAT AGAIN! #AmericaFirst… https://t.co/A4eeHoCbGS\n",
      "Join me live in Reno, Nevada!\n",
      "https://t.co/T4bf1hrxaA https://t.co/EPqRXHa1CM\n",
      "JOIN ME TOMORROW!\n",
      "MINNESOTA • 2pm\n",
      "https://t.co/WcgLh4prS7\n",
      "\n",
      "MICHIGAN • 6pm\n",
      "https://t.co/9BqGVKNNrt\n",
      "\n",
      "VIRGINIA • 9:30p… https://t.co/A1oVhCrT6t\n",
      "#DrainTheSwamp!\n",
      "https://t.co/z68vGp9Bvf\n",
      "Top Clinton Aides Bemoan Campaign ‘All Tactics,’ No Vision: https://t.co/mHYvQtIq78\n",
      "‘Must Act Immediately’: Clinton Charity Lawyer Told Execs They Were Breaking The Law\n",
      "https://t.co/hsi4qhqTV1\n",
      "Watch Coach Mike Ditka- a great guy and supporter tonight at 8pmE on #WattersWorld with @jessebwatters @FoxNews.\n",
      "Thank you Wilmington, North Carolina. We are 3 days away from the CHANGE you've been waiting for your entire life!… https://t.co/6ZJZRBfLST\n",
      "Thank you for the incredible support this morning Tampa, Florida! #ICYMI- watch here: https://t.co/q43kHf7MoE https://t.co/1GscFNaV4L\n"
     ]
    }
   ],
   "source": [
    "# Filter out retweets\n",
    "jack_tweets_no_rts = list(filter(lambda x: not x[1].startswith('RT'), jack_tweets))\n",
    "\n",
    "for i in range(10):\n",
    "    print(jack_tweets_no_rts[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> \n",
      "thank you reno, nevada. \n",
      "nothing will stop us in our quest to make america safe and great again! #americafirst… URL\n",
      "  -> thank you reno, nevada. \n",
      "nothing will stop us in our quest to make america safe and great again! #americafirst… URL\n",
      "join me live in reno, nevada!\n",
      "URL URL\n",
      "  -> join me live in reno, nevada!\n",
      "URL URL\n",
      "join me tomorrow!\n",
      "minnesota • 2pm\n",
      "URL\n",
      "\n",
      "michigan • 6pm\n",
      "URL\n",
      "\n",
      "virginia • 9:30p… URL\n",
      "  -> join me tomorrow!\n",
      "minnesota • 2pm\n",
      "URL\n",
      "\n",
      "michigan • 6pm\n",
      "URL\n",
      "\n",
      "virginia • 9:30p… URL\n",
      "#draintheswamp!\n",
      "URL\n",
      "  -> #draintheswamp!\n",
      "URL\n",
      "top clinton aides bemoan campaign ‘all tactics,’ no vision: URL\n",
      "  -> top clinton aides bemoan campaign ‘all tactics,’ no vision: URL\n",
      "‘must act immediately’: clinton charity lawyer told execs they were breaking the law\n",
      "URL\n",
      "  -> ‘must act immediately’: clinton charity lawyer told execs they were breaking the law\n",
      "URL\n",
      "watch coach mike ditka- a great guy and supporter tonight at 8pme on #wattersworld with @jessebwatters @foxnews.\n",
      "  -> watch coach mike ditka- a great guy and supporter tonight at 8pme on #wattersworld with USER USER.\n",
      "thank you wilmington, north carolina. we are 3 days away from the change you've been waiting for your entire life!… URL\n",
      "  -> thank you wilmington, north carolina. we are 3 days away from the change you've been waiting for your entire life!… URL\n",
      "thank you for the incredible support this morning tampa, florida! #icymi- watch here: URL URL\n",
      "  -> thank you for the incredible support this morning tampa, florida! #icymi- watch here: URL URL\n"
     ]
    }
   ],
   "source": [
    "# Canonicalize the tweet text as lowercase\n",
    "import re\n",
    "jack_tweets_no_rts_lowercase = [tweet[1].lower() for tweet in jack_tweets_no_rts]\n",
    "\n",
    "# Canonicalize links to \"URL\" and @mentions to \"USER\"\n",
    "jack_tweets_no_rts_lowercase = [re.sub(r'(https?:\\/\\/t\\.co\\/\\w+)', 'URL', tweet) for tweet in jack_tweets_no_rts_lowercase]\n",
    "jack_tweets_normalized = [re.sub(r'(@\\w+)', 'USER', tweet) for tweet in jack_tweets_no_rts_lowercase]\n",
    "\n",
    "for i in range(10):\n",
    "    print(jack_tweets_no_rts_lowercase[i])\n",
    "    print(\"  -> {}\".format(jack_tweets_normalized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "# note: need to nltk.download() all the models the first time aroudn\n",
    "\n",
    "# Frequency distribution of words.\n",
    "main_dist = nltk.FreqDist([])\n",
    "for tweet in jack_tweets_normalized:\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # We don't want to count the mentions and hashtags\n",
    "    # tokens = list(filter(lambda x: not (x[0] == '@' or x[0] == '#'), tokens))\n",
    "    \n",
    "    main_dist.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 1095),\n",
       " ('!', 972),\n",
       " ('URL', 875),\n",
       " (',', 863),\n",
       " ('the', 846),\n",
       " ('#', 753),\n",
       " ('to', 517),\n",
       " ('USER', 487),\n",
       " ('and', 468),\n",
       " ('in', 442),\n",
       " ('is', 363),\n",
       " ('of', 359),\n",
       " ('you', 351),\n",
       " (':', 351),\n",
       " ('a', 345),\n",
       " ('i', 295),\n",
       " ('will', 280),\n",
       " ('hillary', 276),\n",
       " ('for', 259),\n",
       " ('thank', 234),\n",
       " ('on', 229),\n",
       " ('``', 191),\n",
       " ('clinton', 191),\n",
       " ('-', 190),\n",
       " ('we', 190),\n",
       " ('at', 173),\n",
       " ('great', 172),\n",
       " (\"''\", 172),\n",
       " ('be', 163),\n",
       " ('that', 157),\n",
       " ('crooked', 151),\n",
       " ('me', 145),\n",
       " ('are', 143),\n",
       " ('it', 139),\n",
       " (\"'s\", 138),\n",
       " (';', 133),\n",
       " ('&', 132),\n",
       " ('amp', 131),\n",
       " ('with', 126),\n",
       " ('by', 117)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dist.most_common()[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hmac\n",
    "import binascii\n",
    "import struct\n",
    "from nltk import word_tokenize\n",
    "\n",
    "hash_key = \"legomystego\"\n",
    "\n",
    "def tweet_hash(tweet):\n",
    "    \"\"\"\n",
    "    Implement a keyed hash function according to section 3.3:\n",
    "    \n",
    "    1. Generate a keyed hash digest (HMAC-MD5) for each word\n",
    "    2. Get the last four bits of the hash\n",
    "    3. Bitwise rotate each value according to its position in the tweet\n",
    "    4. XOR all the values together\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    token_hashes = []\n",
    "    tweet_hash = 0     # Start with 0, the XOR identity\n",
    "    for n, token in enumerate(tokens):\n",
    "        # Generate the keyed hash with the given key\n",
    "        m = hmac.new(hash_key.encode(), msg=token.encode())\n",
    "        \n",
    "        m_hash = m.digest()\n",
    "        \n",
    "        # Get the last nibble of the hash\n",
    "        m_bits = int(m_hash[-1]) & 0x0f\n",
    "        \n",
    "        \n",
    "        # ROT-N for the position in the tweet\n",
    "        for i in range(n):\n",
    "            m_bits_shifted = m_bits << 1\n",
    "            m_bits_overflow = m_bits_shifted & 0xf0\n",
    "            m_bits_lower = m_bits_shifted & 0x0f\n",
    "            \n",
    "            m_bits = m_bits_lower + (m_bits_overflow >> 4)\n",
    "            \n",
    "        tweet_hash ^= m_bits\n",
    "        token_hashes.append(m_bits)\n",
    "        \n",
    "    return hex(tweet_hash)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0xd'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hash(\"ferociosu world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hash(\"world hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x6'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hash(\"magical wonderful magic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Substitutions\n",
    "import sqlite3\n",
    "import dataset\n",
    "RULES_DATABASE_URI = \"sqlite:///ppdb/rules.db\"\n",
    "\n",
    "rules_database = dataset.connect(RULES_DATABASE_URI)\n",
    "lexical_rules = rules_database[\"lexical\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('id', 57148), ('source', 'attraction'), ('target', 'attractiveness'), ('features', '1.0')])]\n"
     ]
    }
   ],
   "source": [
    "print(list(lexical_rules.find(source=\"attraction\")))\n",
    "rules = list(lexical_rules.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attractiveness']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_synonyms(rules, token):\n",
    "    \"\"\"\n",
    "    Get a list of synonyms for the given token\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    token: a string of the token for which to find synonyms\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    a list of synonyms\n",
    "    \"\"\"\n",
    "    return list(set([r['target'] for r in list(rules.find(source=token))]))\n",
    "\n",
    "# Test\n",
    "get_synonyms(lexical_rules, \"attraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_synonyms_for_list(rules, tokens):\n",
    "    \"\"\"\n",
    "    Generate synonyms for each token.\n",
    "    \n",
    "    Return as a dictionary\n",
    "    \"\"\"\n",
    "    synonyms = {}\n",
    "    \n",
    "    for token in tokens:\n",
    "        current_synonyms = get_synonyms(rules, token)\n",
    "        \n",
    "        if current_synonyms:\n",
    "            synonyms[token] = current_synonyms\n",
    "        \n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fairly': ['equitably'], 'attractive': ['appealing']}\n",
      "{'movie': ['film'], 'evening': ['night']}\n"
     ]
    }
   ],
   "source": [
    "print(get_synonyms_for_list(lexical_rules, \"I'm fairly attractive\".split()))\n",
    "print(get_synonyms_for_list(lexical_rules, \"What movie are you seeing this evening\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kenlm\n",
    "model = kenlm.LanguageModel('data/tweets.klm')\n",
    "\n",
    "\n",
    "def get_possible_cover_tweet(rules, tweet):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    synonyms = get_synonyms_for_list(rules, tokens)\n",
    "\n",
    "    # A list of tuples (score, cover tweet)\n",
    "    possibilities = []\n",
    "\n",
    "    for token, alternatives in synonyms.items():\n",
    "        for alt in alternatives:\n",
    "            alt_tweet = tweet.replace(token, alt)\n",
    "            alt_score = model.score(alt_tweet)\n",
    "            \n",
    "            possibilities.append((alt_score, alt_tweet, tweet_hash(alt_tweet)))\n",
    "                        \n",
    "    possibilities = sorted(possibilities, reverse=True)\n",
    "    \n",
    "    for possibility in possibilities:\n",
    "        print(possibility)\n",
    "        \n",
    "    return possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-21.025192260742188, 'what movie do you wanna to see this evening', '0xa')\n",
      "(-23.441560745239258, 'what movie do you want to see this night', '0x4')\n",
      "(-26.4293212890625, 'what film do you want to see this evening', '0xd')\n"
     ]
    }
   ],
   "source": [
    "possibilities = get_possible_cover_tweet(lexical_rules, \"what movie do you want to see this evening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-8.447860717773438, 'i am going to see granny', '0x8')\n",
      "(-11.36048412322998, 'i ben going to see grandma', '0x1')\n",
      "(-11.36048412322998, 'i &apos;m going to see grandma', '0xd')\n",
      "(-12.668585777282715, 'i am going to see grandmother', '0x9')\n"
     ]
    }
   ],
   "source": [
    "possibilities = get_possible_cover_tweet(lexical_rules, \"i am going to see grandma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o2m_rules = rules_database[\"o2m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-9.051159858703613, 'i am going to refer to grandma', '0xd')\n",
      "(-9.095948219299316, 'i am going to see section grandma', '0x8')\n",
      "(-9.444210052490234, 'i am going to get it grandma', '0x0')\n",
      "(-9.453298568725586, 'i am going to consult with grandma', '0xa')\n",
      "(-10.008275985717773, 'i am going to look at grandma', '0x6')\n",
      "(-10.212509155273438, 'i am going to see the section grandma', '0x4')\n",
      "(-10.326525688171387, 'i am going to be seen grandma', '0xa')\n",
      "(-10.354252815246582, 'i am going to colonial see grandma', '0x9')\n",
      "(-10.354252815246582, 'i am going to &apos;s see grandma', '0x5')\n",
      "(-10.354252815246582, 'i am going to &apos;il see grandma', '0x9')\n",
      "(-10.388155937194824, 'i am going to talk to grandma', '0x1')\n",
      "(-10.44310474395752, 'i am going to cf . grandma', '0x3')\n",
      "(-10.533917427062988, 'i am going to to watch grandma', '0x2')\n",
      "(-10.592903137207031, 'i am &apos;s gonna to see grandma', '0xd')\n",
      "(-10.592903137207031, 'i am &apos;re gonna to see grandma', '0xd')\n",
      "(-10.592903137207031, 'i am &apos;m gonna to see grandma', '0xf')\n",
      "(-10.658199310302734, 'i am going to you know grandma', '0x9')\n",
      "(-10.659439086914062, 'i am going to &apos;ve seen grandma', '0x2')\n",
      "(-10.76292610168457, 'i am going to please consult grandma', '0x2')\n",
      "(-11.033719062805176, 'i am going to take a look grandma', '0x5')\n",
      "(-11.128511428833008, 'i am going to &apos;re seeing grandma', '0xb')\n",
      "(-11.128511428833008, 'i am going to &apos;m seeing grandma', '0x3')\n",
      "(-11.12988567352295, 'i am going to are seeing grandma', '0x6')\n",
      "(-11.21989917755127, 'i am going to have seen grandma', '0xf')\n",
      "(-11.31313419342041, 'i am going to see now grandma', '0x6')\n",
      "(-11.416543960571289, 'i am going \\\\ xc3 see grandma', '0x5')\n",
      "(-11.416543960571289, 'i am going -lrb- k see grandma', '0x8')\n",
      "(-11.525483131408691, 'i am going to a look grandma', '0xd')\n",
      "(-11.62501335144043, 'i am &apos;s going to see grandma', '0x5')\n",
      "(-11.62501335144043, 'i am &apos;re going to see grandma', '0x5')\n",
      "(-11.62501335144043, 'i am &apos;m going to see grandma', '0x7')\n",
      "(-11.629011154174805, 'i am going addressed to see grandma', '0x6')\n",
      "(-11.740236282348633, 'i am going to have a look grandma', '0xf')\n",
      "(-11.758583068847656, 'i am going to see what i mean grandma', '0xd')\n",
      "(-11.805951118469238, 'i am going now to see grandma', '0xa')\n",
      "(-11.824525833129883, 'i am going to check out grandma', '0xe')\n",
      "(-11.835026741027832, 'i am going to see here grandma', '0x2')\n",
      "(-11.866521835327148, 'i am going to see him grandma', '0xc')\n",
      "(-11.918058395385742, 'i am going to go see grandma', '0x6')\n",
      "(-12.008572578430176, 'i &apos;m gonna going to see grandma', '0x1')\n",
      "(-12.068157196044922, 'i am &apos;s go to see grandma', '0xb')\n",
      "(-12.289134979248047, 'i am going to check it out grandma', '0x4')\n",
      "(-12.349468231201172, 'i am is gonna to see grandma', '0xf')\n",
      "(-12.537986755371094, 'i am to go to see grandma', '0xa')\n",
      "(-12.634552955627441, 'i am are gonna to see grandma', '0xa')\n",
      "(-13.060957908630371, 'i am going to do with it grandma', '0x8')\n",
      "(-13.099480628967285, 'i am going to know what i mean grandma', '0xd')\n",
      "(-13.174748420715332, 'i am going in order to see grandma', '0xd')\n",
      "(-13.418238639831543, 'i am going to find out grandma', '0xb')\n",
      "(-13.430013656616211, 'i am going to seen him grandma', '0xb')\n",
      "(-13.528434753417969, 'i- i am goi- ing to see grandma', '0xf')\n",
      "(-13.53679084777832, 'i am going to please see grandma', '0x8')\n",
      "(-13.749166488647461, 'i am going to you &apos;re seeing grandma', '0xb')\n",
      "(-13.810464859008789, 'i am going to let &apos;s see grandma', '0x5')\n",
      "(-13.962398529052734, 'i am going to see oh , grandma', '0xd')\n",
      "(-14.055096626281738, 'i am going &apos;s got see grandma', '0xb')\n",
      "(-14.19317626953125, 'i am going to see a grandmother', '0x5')\n",
      "(-14.19979476928711, 'i &apos;s me going to see grandma', '0x3')\n",
      "(-14.31063175201416, 'i am going , in order to see grandma', '0xb')\n",
      "(-14.380242347717285, 'i am going to please visit grandma', '0x4')\n",
      "(-14.415400505065918, 'i am going away to see grandma', '0x5')\n",
      "(-14.477526664733887, 'i am going order to see grandma', '0xd')\n",
      "(-14.644067764282227, 'i am going in order see grandma', '0x9')\n",
      "(-14.647125244140625, 'i &apos;ve got going to see grandma', '0x9')\n",
      "(-14.706466674804688, 'the eu am gothe eung to see grandma', '0x9')\n",
      "(-14.846550941467285, 'i am going of him see grandma', '0x8')\n",
      "(-14.93152904510498, 'i am &apos;s going on to see grandma', '0xb')\n",
      "(-14.959404945373535, 'i &apos;ve am goi &apos;veng to see grandma', '0xc')\n",
      "(-14.959404945373535, 'i &apos;m am goi &apos;mng to see grandma', '0xa')\n",
      "(-15.173048973083496, 'i am going d &quot; see grandma', '0xa')\n",
      "(-15.173048973083496, 'i am going -lrb- d see grandma', '0x9')\n",
      "(-15.334848403930664, 'now i am gonow ing to see grandma', '0x0')\n",
      "(-15.381547927856445, 'here i am gohere ing to see grandma', '0xc')\n",
      "(-15.411163330078125, 'i am getting at to see grandma', '0x6')\n",
      "(-15.438787460327148, 'um , i am goum , ing to see grandma', '0xf')\n",
      "(-15.438787460327148, 'uh , i am gouh , ing to see grandma', '0x9')\n",
      "(-15.479121208190918, 'i am going to see my grandmother', '0xf')\n",
      "(-15.494240760803223, 'i am come on to see grandma', '0x3')\n",
      "(-15.499390602111816, 'i am going to see your grandmother', '0xf')\n",
      "(-15.684184074401855, 'maybe i am gomaybe ing to see grandma', '0x0')\n",
      "(-15.849737167358398, 'i am going view to see grandma', '0xc')\n",
      "(-15.977520942687988, 'then i am gothen ing to see grandma', '0x0')\n",
      "(-16.010215759277344, 'well i am gowell ing to see grandma', '0x2')\n",
      "(-16.05305290222168, '... i am go... ing to see grandma', '0x3')\n",
      "(-16.05842399597168, 'because i am gobecause ing to see grandma', '0x8')\n",
      "(-16.17900276184082, 'i am going in front see grandma', '0xf')\n",
      "(-16.52646255493164, 'well , am gowell ,ng to see grandma', '0x6')\n",
      "(-16.539758682250977, 'i just am goi justng to see grandma', '0x0')\n",
      "(-16.551847457885742, 'i am going to taking in action grandma', '0x6')\n",
      "(-16.555707931518555, 'well , i am gowell , ing to see grandma', '0x1')\n",
      "(-16.958757400512695, 'i am going in order for see grandma', '0xc')\n",
      "(-17.01142692565918, 'look , i am golook , ing to see grandma', '0xb')\n",
      "(-17.039690017700195, 'now , i am gonow , ing to see grandma', '0xc')\n",
      "(-17.087997436523438, 'i got am goi gotng to see grandma', '0x7')\n",
      "(-17.121360778808594, 'i &apos;m on him going to see grandma', '0x9')\n",
      "(-17.217689514160156, 'i am be okay to see grandma', '0xf')\n",
      "(-17.217689514160156, 'i am be fine to see grandma', '0x3')\n",
      "(-17.329343795776367, 'listen , i am golisten , ing to see grandma', '0x4')\n",
      "(-17.33905601501465, 'see , i am gosee , ing to see grandma', '0x5')\n",
      "(-17.851585388183594, 'i am think you &apos;re going to see grandma', '0x7')\n",
      "(-17.899492263793945, 'hey , i am gohey , ing to see grandma', '0x6')\n",
      "(-18.05610466003418, 'oh , i am gooh , ing to see grandma', '0xf')\n",
      "(-18.335376739501953, 'i am going in front of see grandma', '0xf')\n",
      "(-18.436458587646484, 'yes , i am goyes , ing to see grandma', '0x9')\n",
      "(-18.563573837280273, 'i am going with a view see grandma', '0x7')\n",
      "(-18.768367767333984, 'yeah , i am goyeah , ing to see grandma', '0xc')\n",
      "(-18.89413070678711, 'i &apos;ve got am goi &apos;ve gotng to see grandma', '0x7')\n",
      "(-19.42412757873535, 'i am going with a view to see grandma', '0xf')\n",
      "(-19.65951156616211, 'okay , i am gookay , ing to see grandma', '0xc')\n",
      "(-20.59803009033203, 'i am going to me see that for a second grandma', '0xd')\n",
      "(-21.429533004760742, 'i just , i am goi just , ing to see grandma', '0xb')\n",
      "(-21.940528869628906, 'you know , i am goyou know , ing to see grandma', '0xc')\n",
      "(-22.97272491455078, '- well , i am go- well , ing to see grandma', '0x1')\n",
      "(-23.13111686706543, 'i just - i am goi just - ing to see grandma', '0x8')\n",
      "(-24.307178497314453, '- oh , i am go- oh , ing to see grandma', '0x4')\n",
      "(-28.46298599243164, 'yeah , well , i am goyeah , well , ing to see grandma', '0xc')\n",
      "(-9.051159858703613, 'i am going to refer to grandma', '0xd')\n",
      "(-9.095948219299316, 'i am going to see section grandma', '0x8')\n",
      "(-9.444210052490234, 'i am going to get it grandma', '0x0')\n",
      "(-9.453298568725586, 'i am going to consult with grandma', '0xa')\n",
      "(-10.008275985717773, 'i am going to look at grandma', '0x6')\n",
      "(-10.212509155273438, 'i am going to see the section grandma', '0x4')\n",
      "(-10.326525688171387, 'i am going to be seen grandma', '0xa')\n",
      "(-10.354252815246582, 'i am going to colonial see grandma', '0x9')\n",
      "(-10.354252815246582, 'i am going to &apos;s see grandma', '0x5')\n",
      "(-10.354252815246582, 'i am going to &apos;il see grandma', '0x9')\n",
      "(-10.388155937194824, 'i am going to talk to grandma', '0x1')\n",
      "(-10.44310474395752, 'i am going to cf . grandma', '0x3')\n",
      "(-10.533917427062988, 'i am going to to watch grandma', '0x2')\n",
      "(-10.592903137207031, 'i am &apos;s gonna to see grandma', '0xd')\n",
      "(-10.592903137207031, 'i am &apos;re gonna to see grandma', '0xd')\n",
      "(-10.592903137207031, 'i am &apos;m gonna to see grandma', '0xf')\n",
      "(-10.658199310302734, 'i am going to you know grandma', '0x9')\n",
      "(-10.659439086914062, 'i am going to &apos;ve seen grandma', '0x2')\n",
      "(-10.76292610168457, 'i am going to please consult grandma', '0x2')\n",
      "(-11.033719062805176, 'i am going to take a look grandma', '0x5')\n",
      "(-11.128511428833008, 'i am going to &apos;re seeing grandma', '0xb')\n",
      "(-11.128511428833008, 'i am going to &apos;m seeing grandma', '0x3')\n",
      "(-11.12988567352295, 'i am going to are seeing grandma', '0x6')\n",
      "(-11.21989917755127, 'i am going to have seen grandma', '0xf')\n",
      "(-11.31313419342041, 'i am going to see now grandma', '0x6')\n",
      "(-11.416543960571289, 'i am going \\\\ xc3 see grandma', '0x5')\n",
      "(-11.416543960571289, 'i am going -lrb- k see grandma', '0x8')\n",
      "(-11.525483131408691, 'i am going to a look grandma', '0xd')\n",
      "(-11.62501335144043, 'i am &apos;s going to see grandma', '0x5')\n",
      "(-11.62501335144043, 'i am &apos;re going to see grandma', '0x5')\n",
      "(-11.62501335144043, 'i am &apos;m going to see grandma', '0x7')\n",
      "(-11.629011154174805, 'i am going addressed to see grandma', '0x6')\n",
      "(-11.740236282348633, 'i am going to have a look grandma', '0xf')\n",
      "(-11.758583068847656, 'i am going to see what i mean grandma', '0xd')\n",
      "(-11.805951118469238, 'i am going now to see grandma', '0xa')\n",
      "(-11.824525833129883, 'i am going to check out grandma', '0xe')\n",
      "(-11.835026741027832, 'i am going to see here grandma', '0x2')\n",
      "(-11.866521835327148, 'i am going to see him grandma', '0xc')\n",
      "(-11.918058395385742, 'i am going to go see grandma', '0x6')\n",
      "(-12.008572578430176, 'i &apos;m gonna going to see grandma', '0x1')\n",
      "(-12.068157196044922, 'i am &apos;s go to see grandma', '0xb')\n",
      "(-12.289134979248047, 'i am going to check it out grandma', '0x4')\n",
      "(-12.349468231201172, 'i am is gonna to see grandma', '0xf')\n",
      "(-12.537986755371094, 'i am to go to see grandma', '0xa')\n",
      "(-12.634552955627441, 'i am are gonna to see grandma', '0xa')\n",
      "(-13.060957908630371, 'i am going to do with it grandma', '0x8')\n",
      "(-13.099480628967285, 'i am going to know what i mean grandma', '0xd')\n",
      "(-13.174748420715332, 'i am going in order to see grandma', '0xd')\n",
      "(-13.418238639831543, 'i am going to find out grandma', '0xb')\n",
      "(-13.430013656616211, 'i am going to seen him grandma', '0xb')\n",
      "(-13.528434753417969, 'i- i am goi- ing to see grandma', '0xf')\n",
      "(-13.53679084777832, 'i am going to please see grandma', '0x8')\n",
      "(-13.749166488647461, 'i am going to you &apos;re seeing grandma', '0xb')\n",
      "(-13.810464859008789, 'i am going to let &apos;s see grandma', '0x5')\n",
      "(-13.962398529052734, 'i am going to see oh , grandma', '0xd')\n",
      "(-14.055096626281738, 'i am going &apos;s got see grandma', '0xb')\n",
      "(-14.19317626953125, 'i am going to see a grandmother', '0x5')\n",
      "(-14.19979476928711, 'i &apos;s me going to see grandma', '0x3')\n",
      "(-14.31063175201416, 'i am going , in order to see grandma', '0xb')\n",
      "(-14.380242347717285, 'i am going to please visit grandma', '0x4')\n",
      "(-14.415400505065918, 'i am going away to see grandma', '0x5')\n",
      "(-14.477526664733887, 'i am going order to see grandma', '0xd')\n",
      "(-14.644067764282227, 'i am going in order see grandma', '0x9')\n",
      "(-14.647125244140625, 'i &apos;ve got going to see grandma', '0x9')\n",
      "(-14.706466674804688, 'the eu am gothe eung to see grandma', '0x9')\n",
      "(-14.846550941467285, 'i am going of him see grandma', '0x8')\n",
      "(-14.93152904510498, 'i am &apos;s going on to see grandma', '0xb')\n",
      "(-14.959404945373535, 'i &apos;ve am goi &apos;veng to see grandma', '0xc')\n",
      "(-14.959404945373535, 'i &apos;m am goi &apos;mng to see grandma', '0xa')\n",
      "(-15.173048973083496, 'i am going d &quot; see grandma', '0xa')\n",
      "(-15.173048973083496, 'i am going -lrb- d see grandma', '0x9')\n",
      "(-15.334848403930664, 'now i am gonow ing to see grandma', '0x0')\n",
      "(-15.381547927856445, 'here i am gohere ing to see grandma', '0xc')\n",
      "(-15.411163330078125, 'i am getting at to see grandma', '0x6')\n",
      "(-15.438787460327148, 'um , i am goum , ing to see grandma', '0xf')\n",
      "(-15.438787460327148, 'uh , i am gouh , ing to see grandma', '0x9')\n",
      "(-15.479121208190918, 'i am going to see my grandmother', '0xf')\n",
      "(-15.494240760803223, 'i am come on to see grandma', '0x3')\n",
      "(-15.499390602111816, 'i am going to see your grandmother', '0xf')\n",
      "(-15.684184074401855, 'maybe i am gomaybe ing to see grandma', '0x0')\n",
      "(-15.849737167358398, 'i am going view to see grandma', '0xc')\n",
      "(-15.977520942687988, 'then i am gothen ing to see grandma', '0x0')\n",
      "(-16.010215759277344, 'well i am gowell ing to see grandma', '0x2')\n",
      "(-16.05305290222168, '... i am go... ing to see grandma', '0x3')\n",
      "(-16.05842399597168, 'because i am gobecause ing to see grandma', '0x8')\n",
      "(-16.17900276184082, 'i am going in front see grandma', '0xf')\n",
      "(-16.52646255493164, 'well , am gowell ,ng to see grandma', '0x6')\n",
      "(-16.539758682250977, 'i just am goi justng to see grandma', '0x0')\n",
      "(-16.551847457885742, 'i am going to taking in action grandma', '0x6')\n",
      "(-16.555707931518555, 'well , i am gowell , ing to see grandma', '0x1')\n",
      "(-16.958757400512695, 'i am going in order for see grandma', '0xc')\n",
      "(-17.01142692565918, 'look , i am golook , ing to see grandma', '0xb')\n",
      "(-17.039690017700195, 'now , i am gonow , ing to see grandma', '0xc')\n",
      "(-17.087997436523438, 'i got am goi gotng to see grandma', '0x7')\n",
      "(-17.121360778808594, 'i &apos;m on him going to see grandma', '0x9')\n",
      "(-17.217689514160156, 'i am be okay to see grandma', '0xf')\n",
      "(-17.217689514160156, 'i am be fine to see grandma', '0x3')\n",
      "(-17.329343795776367, 'listen , i am golisten , ing to see grandma', '0x4')\n",
      "(-17.33905601501465, 'see , i am gosee , ing to see grandma', '0x5')\n",
      "(-17.851585388183594, 'i am think you &apos;re going to see grandma', '0x7')\n",
      "(-17.899492263793945, 'hey , i am gohey , ing to see grandma', '0x6')\n",
      "(-18.05610466003418, 'oh , i am gooh , ing to see grandma', '0xf')\n",
      "(-18.335376739501953, 'i am going in front of see grandma', '0xf')\n",
      "(-18.436458587646484, 'yes , i am goyes , ing to see grandma', '0x9')\n",
      "(-18.563573837280273, 'i am going with a view see grandma', '0x7')\n",
      "(-18.768367767333984, 'yeah , i am goyeah , ing to see grandma', '0xc')\n",
      "(-18.89413070678711, 'i &apos;ve got am goi &apos;ve gotng to see grandma', '0x7')\n",
      "(-19.42412757873535, 'i am going with a view to see grandma', '0xf')\n",
      "(-19.65951156616211, 'okay , i am gookay , ing to see grandma', '0xc')\n",
      "(-20.59803009033203, 'i am going to me see that for a second grandma', '0xd')\n",
      "(-21.429533004760742, 'i just , i am goi just , ing to see grandma', '0xb')\n",
      "(-21.940528869628906, 'you know , i am goyou know , ing to see grandma', '0xc')\n",
      "(-22.97272491455078, '- well , i am go- well , ing to see grandma', '0x1')\n",
      "(-23.13111686706543, 'i just - i am goi just - ing to see grandma', '0x8')\n",
      "(-24.307178497314453, '- oh , i am go- oh , ing to see grandma', '0x4')\n",
      "(-28.46298599243164, 'yeah , well , i am goyeah , well , ing to see grandma', '0xc')\n"
     ]
    }
   ],
   "source": [
    "possibilities_o2m = get_possible_cover_tweet(o2m_rules, \"i am going to see grandma\")\n",
    "possibilities_lexical = get_possible_cover_tweet(o2m_rules, \"i am going to see grandma\")\n",
    "\n",
    "possibilities = []\n",
    "possibilities.extend(possibilities_o2m)\n",
    "possibilities.extend(possibilities_lexical)\n",
    "possibilities = list(set(possibilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possibilities = sorted(possibilities, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: these are possibities within the  the language model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualEnv Python 3.5 Stego",
   "language": "python",
   "name": "ipykernel-stego"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
